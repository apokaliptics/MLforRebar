---
title: "HealthContradict: Evaluating Biomedical Knowledge Conflicts in Language Models"
authors: "Boya Zhang, Alban Bornet, Rui Yang, Nan Liu, Douglas Teodoro"
categories: "cs.CL, cs.AI"
source: "http://arxiv.org/abs/2512.02299v1"
pdf: "https://arxiv.org/pdf/2512.02299v1"
---

## Abstract

How do language models use contextual information to answer health questions? How are their responses impacted by conflicting contexts? We assess the ability of language models to reason over long, conflicting biomedical contexts using HealthContradict, an expert-verified dataset comprising 920 unique instances, each consisting of a health-related question, a factual answer supported by scientific evidence, and two documents presenting contradictory stances. We consider several prompt settings, including correct, incorrect or contradictory context, and measure their impact on model outputs. Compared to existing medical question-answering evaluation benchmarks, HealthContradict provides greater distinctions of language models' contextual reasoning capabilities. Our experiments show that the strength of fine-tuned biomedical language models lies not only in their parametric knowledge from pretraining, but also in their ability to exploit correct context while resisting incorrect context.
