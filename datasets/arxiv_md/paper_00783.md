---
title: "Prompt Repetition Improves Non-Reasoning LLMs"
authors: "Yaniv Leviathan, Matan Kalman, Yossi Matias"
categories: "cs.LG, cs.AI, cs.CL"
source: "http://arxiv.org/abs/2512.14982v1"
pdf: "https://arxiv.org/pdf/2512.14982v1"
---

## Abstract

When not using reasoning, repeating the input prompt improves performance for popular models (Gemini, GPT, Claude, and Deepseek) without increasing the number of generated tokens or latency.
