---
title: "Enforcing Orderedness to Improve Feature Consistency"
authors: "Sophie L. Wang, Alex Quach, Nithin Parsan, John J. Yang"
categories: "cs.LG, cs.AI"
source: "http://arxiv.org/abs/2512.02194v1"
pdf: "https://arxiv.org/pdf/2512.02194v1"
---

## Abstract

Sparse autoencoders (SAEs) have been widely used for interpretability of neural networks, but their learned features often vary across seeds and hyperparameter settings. We introduce Ordered Sparse Autoencoders (OSAE), which extend Matryoshka SAEs by (1) establishing a strict ordering of latent features and (2) deterministically using every feature dimension, avoiding the sampling-based approximations of prior nested SAE methods. Theoretically, we show that OSAEs resolve permutation non-identifiability in settings of sparse dictionary learning where solutions are unique (up to natural symmetries). Empirically on Gemma2-2B and Pythia-70M, we show that OSAEs can help improve consistency compared to Matryoshka baselines.
