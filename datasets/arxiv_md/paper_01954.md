---
title: "TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models"
authors: "Shima Imani, Seungwhan Moon, Lambert Mathias, Lu Zhang, Babak Damavandi"
categories: "cs.AI"
source: "http://arxiv.org/abs/2512.05943v3"
pdf: "https://arxiv.org/pdf/2512.05943v3"
---

## Abstract

Reliable mathematical and scientific reasoning remains an open challenge for large vision-language models. Standard final-answer evaluation often masks reasoning errors, allowing silent failures to persist. To address this gap, we introduce TRACE, a framework for Transparent Reasoning And Consistency Evaluation that diagnoses reasoning trajectories rather than only end results. At its core, TRACE leverages Auxiliary Reasoning Sets, compact sub question answer pairs that decompose complex problems, evaluate intermediate steps through consistency-based metrics, and expose failures overlooked by standard evaluation. Our experiments show that consistency across ARS correlates with final-answer correctness and helps pinpoint the reasoning steps where failures arise, offering actionable signals for model improvement. Furthermore, TRACE defines confidence regions that distinguish reliable from unreliable reasoning paths, supporting effective filtering, debugging, and model refinement.
