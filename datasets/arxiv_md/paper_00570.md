---
title: "Plain language adaptations of biomedical text using LLMs: Comparision of evaluation metrics"
authors: "Primoz Kocbek, Leon Kopitar, Gregor Stiglic"
categories: "cs.CL, cs.AI"
source: "http://arxiv.org/abs/2512.16530v1"
pdf: "https://arxiv.org/pdf/2512.16530v1"
---

## Abstract

This study investigated the application of Large Language Models (LLMs) for simplifying biomedical texts to enhance health literacy. Using a public dataset, which included plain language adaptations of biomedical abstracts, we developed and evaluated several approaches, specifically a baseline approach using a prompt template, a two AI agent approach, and a fine-tuning approach. We selected OpenAI gpt-4o and gpt-4o mini models as baselines for further research. We evaluated our approaches with quantitative metrics, such as Flesch-Kincaid grade level, SMOG Index, SARI, and BERTScore, G-Eval, as well as with qualitative metric, more precisely 5-point Likert scales for simplicity, accuracy, completeness, brevity. Results showed a superior performance of gpt-4o-mini and an underperformance of FT approaches. G-Eval, a LLM based quantitative metric, showed promising results, ranking the approaches similarly as the qualitative metric.
