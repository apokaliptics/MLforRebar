---
title: "Concept Generalization in Humans and Large Language Models: Insights from the Number Game"
authors: "Arghavan Bazigaran, Hansem Sohn"
categories: "cs.AI"
source: "http://arxiv.org/abs/2512.20162v1"
pdf: "https://arxiv.org/pdf/2512.20162v1"
---

## Abstract

We compare human and large language model (LLM) generalization in the number game, a concept inference task. Using a Bayesian model as an analytical framework, we examined the inductive biases and inference strategies of humans and LLMs. The Bayesian model captured human behavior better than LLMs in that humans flexibly infer rule-based and similarity-based concepts, whereas LLMs rely more on mathematical rules. Humans also demonstrated a few-shot generalization, even from a single example, while LLMs required more samples to generalize. These contrasts highlight the fundamental differences in how humans and LLMs infer and generalize mathematical concepts.
