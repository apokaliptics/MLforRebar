---
title: "LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms"
authors: "Ali Parsaee, Yashar Talebirad, Csongor Szepesv√°ri, Vishwajeet Ohal, Eden Redman"
categories: "cs.AI, cs.LG, cs.MA"
source: "http://arxiv.org/abs/2512.13713v1"
pdf: "https://arxiv.org/pdf/2512.13713v1"
---

## Abstract

Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed symmetry breaking and meta-cognitive thinking. The benchmark focuses on coloring odd cycle graphs ($C_3, C_5, C_{11}$) with limited colors, where deterministic, non-communicating agents fail in infinite loops. A strategy passing mechanism is implemented as a form of consistent memory. We show that while standard LLMs and classical heuristics struggle, advanced reasoning models (e.g., O3) devise strategies to escape deadlocks. LoopBench allows the study of emergent distributed algorithms based on language-based reasoning, offering a testbed for collective intelligence.
