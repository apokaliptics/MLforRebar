---
title: "Learning Robust Representations for Malicious Content Detection via Contrastive Sampling and Uncertainty Estimation"
authors: "Elias Hossain, Umesh Biswas, Charan Gudla, Sai Phani Parsa"
categories: "cs.LG, cs.AI"
source: "http://arxiv.org/abs/2512.08969v1"
pdf: "https://arxiv.org/pdf/2512.08969v1"
---

## Abstract

We propose the Uncertainty Contrastive Framework (UCF), a Positive-Unlabeled (PU) representation learning framework that integrates uncertainty-aware contrastive loss, adaptive temperature scaling, and a self-attention-guided LSTM encoder to improve classification under noisy and imbalanced conditions. UCF dynamically adjusts contrastive weighting based on sample confidence, stabilizes training using positive anchors, and adapts temperature parameters to batch-level variability. Applied to malicious content classification, UCF-generated embeddings enable multiple traditional classifiers to achieve more than 93.38% accuracy, precision above 0.93, and near-perfect recall, with minimal false negatives and competitive ROC-AUC scores. Visual analyses confirm clear separation between positive and unlabeled instances, highlighting the framework's ability to produce calibrated, discriminative embeddings. These results position UCF as a robust and scalable solution for PU learning in high-stakes domains such as cybersecurity and biomedical text mining.
