---
title: "Soft Geometric Inductive Bias for Object Centric Dynamics"
authors: "Hampus Linander, Conor Heins, Alexander Tschantz, Marco Perin, Christopher Buckley"
categories: "cs.LG, cs.AI, stat.ML"
source: "http://arxiv.org/abs/2512.15493v1"
pdf: "https://arxiv.org/pdf/2512.15493v1"
---

## Abstract

Equivariance is a powerful prior for learning physical dynamics, yet exact group equivariance can degrade performance if the symmetries are broken. We propose object-centric world models built with geometric algebra neural networks, providing a soft geometric inductive bias. Our models are evaluated using simulated environments of 2d rigid body dynamics with static obstacles, where we train for next-step predictions autoregressively. For long-horizon rollouts we show that the soft inductive bias of our models results in better performance in terms of physical fidelity compared to non-equivariant baseline models. The approach complements recent soft-equivariance ideas and aligns with the view that simple, well-chosen priors can yield robust generalization. These results suggest that geometric algebra offers an effective middle ground between hand-crafted physics and unstructured deep nets, delivering sample-efficient dynamics models for multi-object scenes.
