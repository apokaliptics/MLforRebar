{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60763254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0 — Sanity check (30 seconds)\n",
    "import sklearn\n",
    "import pandas\n",
    "print('ML environment ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e30d21",
   "metadata": {},
   "source": [
    "## STEP 2 — Get your essays into the notebook\n",
    "\n",
    "This loads all `.md` files in the workspace root into a list `docs` where each entry is a dict with `text`, `path` and `paragraphs` (split on blank lines). If you prefer to use `.txt` files instead, drop them into the workspace and this will pick them up as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "ROOT = Path('.')\n",
    "md_files = list(ROOT.glob('*.md'))\n",
    "docs = []\n",
    "for p in md_files:\n",
    "    text = p.read_text(encoding='utf-8')\n",
    "    # simple paragraph split on blank lines\n",
    "    paragraphs = [pb.strip() for pb in re.split(r'\n",
    "*\n",
    "', text) if pb.strip()]\n",
    "    docs.append({'path': str(p), 'text': text, 'paragraphs': paragraphs})\n",
    "\n",
    "len(docs), md_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2edcf5",
   "metadata": {},
   "source": [
    "## STEP 3 — Create Label Studio tasks (one candidate per inter-sentence boundary)\n",
    "\n",
    "We create a JSONL `labelstudio_tasks.jsonl` where each task has `text_before`, `text_after`, `full_paragraph`, `doc`, `paragraph_index`, and `boundary_index`. Import into Label Studio using the *Import -> Tasks* menu (JSONL).\n",
    "Label schema (labeling_config.xml) will show both sides and a 2-choice task: `split` / `no_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9eccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "def sentence_split(paragraph):\n",
    "    sents = [s.strip() for s in tokenize.sent_tokenize(paragraph) if s.strip()]\n",
    "    return sents\n",
    "\n",
    "tasks = []\n",
    "for doc in docs:\n",
    "    for pi, para in enumerate(doc['paragraphs']):\n",
    "        sents = sentence_split(para)\n",
    "        # skip short paragraphs\n",
    "        if len(sents) < 2:\n",
    "            continue\n",
    "        for bi in range(len(sents)-1):\n",
    "            before = ' '.join(sents[:bi+1])\n",
    "            after = ' '.join(sents[bi+1:])\n",
    "            tasks.append({'data': {'text_before': before, 'text_after': after, 'full_paragraph': para, 'doc': doc['path'], 'paragraph_index': pi, 'boundary_index': bi}})\n",
    "\n",
    "out_path = ROOT / 'labelstudio_tasks.jsonl'\n",
    "with open(out_path, 'w', encoding='utf-8') as f:\n",
    "    for t in tasks:\n",
    "        f.write(json.dumps(t, ensure_ascii=False) + '\n",
    "')\n",
    "\n",
    "print('Wrote', len(tasks), 'tasks to', out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d4604",
   "metadata": {},
   "source": [
    "## Labeling config (for Label Studio) — use `labeling_config.xml` in the repo and import it as the project labeling config.\n",
    "\n",
    "This shows `text_before` and `text_after` and a Choices control with `split` and `no_split`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6bdd73",
   "metadata": {},
   "source": [
    "## After labeling — converting export to features and labels\n",
    "\n",
    "Export your completed tasks from Label Studio (JSON export). Download it and place it at `labelstudio_export.json` in workspace root. Then run the cell below to convert it to a CSV suitable for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036644a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, csv\n",
    "from statistics import mean\n",
    "\n",
    "def extract_features(text):\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    sentence_count = len([s for s in sentences if s.strip()])\n",
    "    avg_sentence_length = sum(len(s.split()) for s in sentences if s.strip()) / max(1, sentence_count)\n",
    "    comma_count = text.count(',')\n",
    "    return [sentence_count, avg_sentence_length, comma_count]\n",
    "\n",
    "def ls_export_to_training(export_path='labelstudio_export.json', out_csv='training_data.csv'):\n",
    "    with open(export_path, 'r', encoding='utf-8') as f:\n",
    "        records = json.load(f)\n",
    "    rows = []\n",
    "    for r in records:\n",
    "        # Label Studio structure: predictions or annotations with results -> choices\n",
    "        data = r.get('data', {})\n",
    "        # Find completed annotation with choices result\n",
    "        ann = None\n",
    "        for a in r.get('annotations', []) + r.get('predictions', []):\n",
    "            ann = a\n",
    "            break\n",
    "        if not ann:\n",
    "            continue\n",
    "        # try to find choice result\n",
    "        results = ann.get('result', [])\n",
    "        choice = None\n",
    "        for res in results:\n",
    "            if res.get('type') == 'choices' or res.get('type') == 'singlechoice':\n",
    "                choice = res.get('value', {}).get('choices') or res.get('value')\n",
    "                break\n",
    "        if not choice:\n",
    "            continue\n",
    "        label = 1 if 'split' in choice else 0\n",
    "        before = data.get('text_before')\n",
    "        after = data.get('text_after')\n",
    "        full = data.get('full_paragraph', before + ' ' + after)\n",
    "        features = extract_features(full)\n",
    "        rows.append({'label': label, 'features': features, 'doc': data.get('doc'), 'paragraph_index': data.get('paragraph_index'), 'boundary_index': data.get('boundary_index')})\n",
    "    # write CSV with simple columns\n",
    "    with open(out_csv, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['label', 'sentence_count', 'avg_sentence_length', 'comma_count', 'doc', 'paragraph_index', 'boundary_index'])\n",
    "        for r in rows:\n",
    "            writer.writerow([r['label']] + r['features'] + [r['doc'], r['paragraph_index'], r['boundary_index']])\n",
    "    print('Wrote training CSV with', len(rows), 'rows to', out_csv)\n",
    "\n",
    "# Example: ls_export_to_training('labelstudio_export.json', 'training_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f6132",
   "metadata": {},
   "source": [
    "## STEP 5 — Train a tiny ML model (Logistic Regression)\n",
    "\n",
    "Run the next cell after you have `training_data.csv` created by the previous step. This trains, prints metrics, inspects `coef_`, and exports the model JSON for Rebar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import json\n",
    "\n",
    "def train_and_export(csv_path='training_data.csv', model_out='paragraph_split_model.json'):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            feats = [float(row['sentence_count']), float(row['avg_sentence_length']), float(row['comma_count'])]\n",
    "            X.append(feats)\n",
    "            y.append(int(row['label']))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print('Accuracy:', accuracy_score(y_test, preds))\n",
    "    print(classification_report(y_test, preds))\n",
    "    print('Weights:', model.coef_, 'Bias:', model.intercept_)\n",
    "    model_data = {'weights': model.coef_[0].tolist(), 'bias': float(model.intercept_[0])}\n",
    "    with open(model_out, 'w', encoding='utf-8') as f:\n",
    "        json.dump(model_data, f)\n",
    "    print('Exported model to', model_out)\n",
    "\n",
    "# Example: train_and_export('training_data.csv', 'paragraph_split_model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d05b8",
   "metadata": {},
   "source": [
    "## STEP 8 — Use this inside Rebar (TypeScript snippet)\n",
    "\n",
    "Below is the snippet to run inside Rebar after you `git add` the `paragraph_split_model.json` to your assets. Put this into the Rebar scoring / suggestion code.\n",
    "\n",
    "```ts\n",
    "function score(features: number[], model: {weights:number[], bias:number}){\n",
    "  return features.reduce((s,f,i) => s + f*model.weights[i], model.bias);\n",
    "}\n",
    "if (score(features, model) > 0) { suggestSplitParagraph(); }\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
